use futures::FutureExt;
use parking_lot::lock_api::RwLock;
use parking_lot::Mutex;
use prometheus::core::{Atomic, AtomicF64};
use rand::{thread_rng, Rng};
use ratelimit::Ratelimiter;
use tokio::time::Sleep;

// use core::panicking::panic;
use std::any::TypeId;
use std::collections::{BTreeMap, HashMap, VecDeque};
use std::pin::Pin;
use std::sync::atomic::{AtomicU32, AtomicU64, Ordering};
use std::task::Waker;
use std::time::{Duration, Instant, SystemTime, UNIX_EPOCH};
use std::{
    future::Future,
    sync::Arc,
    task::{Context, Poll},
};

use super::runtime_handle::{CommonRuntimeHandle, Ms10, RateLimiterRuntimeHandle};
use crate::priority::{self, Priority};

struct OneFutureRecord {
    total_micro: u64,
    cpu_micro: u64,
}

// static ref EACH_FUTURE_RECORD: parking_lot::RwLock<Option<std::sync::mpsc::Sender<(Priority,Waker)>>> = RwLock::new(None);

lazy_static::lazy_static! {
    // static ref EACH_FUTURE_RECORD: parking_lot::RwLock<HashMap<TypeId, VecDeque<OneFutureRecord>>>> = RwLock::new(HashMap::new());
    static ref EACH_FUTURE_POLL_TIME: parking_lot::RwLock<HashMap<TypeId, AtomicU64>> = RwLock::new(HashMap::new());
}

enum State {
    Common,
    Backoff(Pin<Box<Sleep>>),
}
impl State {
    fn unwrap_backoff(&mut self) -> &mut Pin<Box<Sleep>> {
        match self {
            State::Backoff(sleep) => sleep,
            _ => panic!("unwrap_backoff failed"),
        }
    }
}

#[pin_project::pin_project]
pub struct PendingFuture<F: Future + Send + 'static> {
    #[pin]
    future: F,
    /// priority of this future
    handle: RateLimiterRuntimeHandle,
    /// count of pendings
    pub pend_cnt: u32, // track the pending count for test
    /// count of inserted pendings
    // pub inserted_pend_cnt: u32,
    // sche_time: u32,
    // poll_time: u32,
    state: State,
}

impl<F> PendingFuture<F>
where
    F: Future + Send + 'static,
    F::Output: Send + 'static,
{
    pub fn new(handle: RateLimiterRuntimeHandle, future: F) -> Self {
        Self {
            future,
            handle,
            pend_cnt: 0,
            // inserted_pend_cnt: 0,
            state: State::Common,
            // poll_time: 0,
            // sche_time: 0,
        }
    }
}

// impl<F> PendingFuture<F> for CountModePendingFuture<F>
// where
//     F: Future + Send + 'static,
//     F::Output: Send + 'static,
// {
//     fn new(priority: Priority, future: F) -> Self {
//         Self::new(priority, future)
//     }

//     fn pend_cnt_track(&self) -> Arc<u32> {
//         self.pend_cnt.clone()
//     }
// }

impl<F> Future for PendingFuture<F>
where
    F: Future + Send + 'static,
    F::Output: Send + 'static,
{
    type Output = F::Output;

    fn poll(self: std::pin::Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        let this = self.project();
        // let sche_begin = Instant::now();
        match this.state {
            State::Common => {}
            State::Backoff(ref mut sleep) => match sleep.poll_unpin(cx) {
                Poll::Ready(_) => {
                    *this.state = State::Common;
                    // this.handle.1 .3.fetch_sub(1, Ordering::Relaxed);
                }
                Poll::Pending => return Poll::Pending,
            },
        };

        // let inter = 5;

        // if (*this.pend_cnt + 1) % inter == 0 {
        // let mut added = 0;
        let mut cursum = 0;
        if let Some(ratelimiter) = &this.handle.0 {
            *this.pend_cnt += 1;
            let limit = match this.handle.2 {
                Priority::VeryLow => 100000,
                Priority::Low => 100000,
                Priority::Middle => 100000,
                Priority::High => 150000,
                Priority::VeryHigh => 30000000,
            };
            // let limit = 30000000;

            let now = SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .unwrap()
                .as_millis() as u64;
            loop {
                let last_reset_time = this.handle.1 .3.load(Ordering::SeqCst);
                if now > last_reset_time && now - last_reset_time > 10 {
                    if this
                        .handle
                        .1
                         .3
                        .compare_exchange(last_reset_time, now, Ordering::SeqCst, Ordering::SeqCst)
                        .is_ok()
                    {
                        this.handle.1 .2.store(0, Ordering::SeqCst);
                        break;
                    }
                } else {
                    break;
                }
            }

            let recent_time_sum =
                if let Some(v) = EACH_FUTURE_POLL_TIME.read().get(&TypeId::of::<F>()) {
                    let v = v.load(Ordering::SeqCst);
                    // println!("future avg poll time: {}", v);
                    // added = v;
                    cursum = this.handle.1 .2.fetch_add(v, Ordering::SeqCst);
                    // println!(
                    //     "--> {} {} {}",
                    //     cursum,
                    //     v,
                    //     (&this.handle.1 .2) as *const _ as usize,
                    // );
                    cursum.checked_add(v).unwrap_or_else(|| {
                        panic!("{} {}", cursum, v);
                    })
                } else {
                    this.handle.1 .2.load(Ordering::SeqCst)
                };
            // println!("recent time sum {}", recent_time_sum);

            if recent_time_sum > limit {
                let will_sleep = 10; //10 + this.handle.1 .3.load(Ordering::Relaxed);
                                     // println!("will sleep {}", will_sleep);
                                     // if let Err(wait) = ratelimiter.try_wait() {
                *this.state = State::Backoff(Box::pin(tokio::time::sleep(
                    Duration::from_millis(will_sleep), // wait,
                                                       // std::time::Duration::from_millis(
                                                       // pend_period as u64 + thread_rng().gen_range(0..10),
                                                       // 20,
                                                       // ((diff + 9) / 7) as u64 + 5,
                                                       // ),
                )));
                match this.state.unwrap_backoff().poll_unpin(cx) {
                    Poll::Ready(_) => {
                        *this.state = State::Common;
                        cx.waker().clone().wake();
                        // *this.sche_time += sche_begin.elapsed().as_micros() as u32;
                        return Poll::Pending;
                    }
                    Poll::Pending => {
                        // this.handle.1 .3.fetch_add(1, Ordering::Relaxed);
                        // *this.sche_time += sche_begin.elapsed().as_micros() as u32;
                        return Poll::Pending;
                    }
                }
            }
        }

        // }
        // *this.sche_time += sche_begin.elapsed().as_micros() as u32;
        let poll_begin = Instant::now();
        let poll_res = this.future.poll(cx);
        let poll_time = poll_begin.elapsed().as_micros() as u64;
        // let now_ms10 = SystemTime::now()
        //     .duration_since(UNIX_EPOCH)
        //     .unwrap()
        //     .as_millis() as Ms10
        //     / 10;

        // if poll_time < added {
        //     loop {
        //         let cur = this.handle.1 .2.load(Ordering::SeqCst);
        //         if cur + poll_time < added {
        //             break;
        //         }
        //         if this
        //             .handle
        //             .1
        //              .2
        //             .compare_exchange(
        //                 cur,
        //                 cur + poll_time - added,
        //                 Ordering::SeqCst,
        //                 Ordering::SeqCst,
        //             )
        //             .is_ok()
        //         {
        //             break;
        //         }
        //     }
        //     // this.handle
        //     //     .1
        //     //      .2
        //     //     .fetch_sub(added - poll_time, Ordering::SeqCst);
        // } else {
        //     this.handle
        //         .1
        //          .2
        //         .fetch_add(poll_time - added, Ordering::SeqCst);
        // }

        let read = EACH_FUTURE_POLL_TIME.read();
        if let Some(v) = read.get(&TypeId::of::<F>()) {
            v.store(
                (v.load(Ordering::Relaxed) + poll_time) / 2,
                Ordering::Relaxed,
            );
        } else {
            drop(read);
            EACH_FUTURE_POLL_TIME
                .write()
                .insert(TypeId::of::<F>(), AtomicU64::new(poll_time));
        }

        // this.handle.1 .1.send((now_ms10, poll_time));

        match poll_res {
            Poll::Ready(r) => {
                // println!("sche time {}, poll time {}", this.sche_time, this.poll_time);
                Poll::Ready(r)
            }
            Poll::Pending => {
                *this.pend_cnt += 1;
                Poll::Pending
            }
        }
    }
}

// #[cfg(test)]
// mod tests {
//     use super::PendingFuture;
//     use crate::priority::Priority;
//     use crate::{test_effect, test_pend_cnt};
//     use std::sync::atomic::Ordering;

//     async fn hello1() {
//         println!("hello1");
//     }

//     async fn hello2() {
//         println!("hello2");
//     }

//     #[async_trait::async_trait]
//     trait AsyncTraitHello {
//         async fn hello(&self);
//     }

//     struct Hello;
//     #[async_trait::async_trait]
//     impl AsyncTraitHello for Hello {
//         async fn hello(&self) {
//             println!("hello3")
//         }
//     }

//     #[tokio::test]
//     async fn test_multi_await_no_pend() {
//         let future = PendingFuture::new(Priority::Middle, async {
//             // on stack future
//             hello1().await;
//             hello2().await;
//             // box dyn future,
//             // The absence of pend could be due to compiler optimizations,
//             //  or it could be related to the future generation mechanism.
//             let f = Hello.hello();
//             f.await;
//             async { 42 }.await;
//             42
//         });
//         let pend_cnt = future.pend_cnt.clone();

//         tokio::spawn(async move {
//             let _ = future.await;
//         })
//         .await
//         .unwrap();
//         assert_eq!(0, pend_cnt.load(Ordering::Acquire));
//     }

//     #[tokio::test]
//     async fn test_pend_cnt() {
//         test_pend_cnt!(mode_count);
//     }

//     #[tokio::test]
//     async fn test_effect() {
//         test_effect!(mode_count);
//     }
// }
